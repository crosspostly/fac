# -*- coding: utf-8 -*-
import os
import requests
import subprocess
import time
import datetime
import json
import sqlite3
import shutil
import config

# Import social uploader
try:
    from social_uploader import process_social_uploads, get_video_orientation
except ImportError:
    print("‚ö†Ô∏è Social uploader module not found.")
    process_social_uploads = None
    get_video_orientation = lambda x: 'horizontal' # Fallback

# Lazy import placeholder
set_cover_frame = None

# Try importing Playwright module safely
try:
    from set_frame_playwright import set_cover_frame
except ImportError:
    print("‚ö†Ô∏è Playwright module not found. Cover frame will not be set.")

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
LOGIN = config.RUTUBE_LOGIN
PASSWORD = config.RUTUBE_PASSWORD
PUBLIC_DOMAIN = config.PUBLIC_IP
PORT = config.SERVER_PORT
YOUTUBE_CHANNEL_URL = config.YOUTUBE_CHANNEL_URL
UPLOADS_DIR = config.UPLOADS_DIR
DB_FILE = config.DB_FILE

# Metadata cache file for quick lookups
METADATA_CACHE_FILE = "video_metadata_cache.json"

# Resolve yt-dlp path
YT_DLP_PATH = config.YT_DLP_PATH
if not os.path.exists(YT_DLP_PATH) or not os.access(YT_DLP_PATH, os.X_OK):
    print(f"‚ö†Ô∏è Configured YT_DLP_PATH '{YT_DLP_PATH}' is not valid.")
    system_yt = shutil.which("yt-dlp")
    if system_yt:
        print(f"‚úÖ Using system yt-dlp: {system_yt}")
        YT_DLP_PATH = system_yt
    else:
        print("‚ùå CRITICAL: No yt-dlp found!")

def log(msg):
    print(f"[{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {msg}")

def init_db():
    conn = sqlite3.connect(DB_FILE)
    conn.execute('CREATE TABLE IF NOT EXISTS synced (y_id TEXT PRIMARY KEY, title TEXT)')
    conn.commit()
    conn.close()

def is_video_synced(y_id):
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.execute('SELECT 1 FROM synced WHERE y_id=?', (y_id,))
    exists = cursor.fetchone()
    conn.close()
    return exists is not None

def mark_video_synced(y_id, title):
    conn = sqlite3.connect(DB_FILE)
    conn.execute('INSERT OR REPLACE INTO synced VALUES (?, ?)', (y_id, title))
    conn.commit()
    conn.close()

def load_metadata_cache():
    """Load cached video metadata to avoid repeated API calls"""
    if os.path.exists(METADATA_CACHE_FILE):
        try:
            with open(METADATA_CACHE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            pass
    return {}

def save_metadata_cache(cache):
    """Save video metadata cache"""
    try:
        with open(METADATA_CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(cache, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—ç—à–∞: {e}")

def get_auth_token():
    r = requests.post("https://rutube.ru/api/accounts/token_auth/", data={'username': LOGIN, 'password': PASSWORD})
    return r.json().get('token') if r.status_code == 200 else None

def wait_for_processing(video_id, token, max_retries=120, delay=5):
    headers = {"Authorization": f"Token {token}"}
    for i in range(max_retries):
        try:
            r = requests.get(f"https://rutube.ru/api/video/{video_id}/", headers=headers)
            if r.status_code == 200:
                data = r.json()
                status = data.get('status')
                action_reason = data.get('action_reason', {}).get('name')
                is_deleted = data.get('is_deleted')

                if status == 'ready' or action_reason == 'moderation':
                    return True
                
                if status == 'error' or (is_deleted and action_reason != 'downloading_video'):
                    log(f"‚ùå –í–∏–¥–µ–æ –ø–µ—Ä–µ—à–ª–æ –≤ —Å—Ç–∞—Ç—É—Å {status} –∏–ª–∏ —É–¥–∞–ª–µ–Ω–æ (reason: {action_reason})")
                    return False
            else:
                log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞: {r.status_code}")
        except Exception as e:
            log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç–∞—Ç—É—Å–∞: {e}")
        
        time.sleep(delay)
    
    log("‚è∞ –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ")
    return False

def get_full_video_info(y_id, metadata_cache=None):
    """Fetches full video metadata with caching and retry logic"""
    
    # Check cache first
    if metadata_cache and y_id in metadata_cache:
        log(f"üìÑ –ú–µ—Ç–∞–¥–∞—Ç–∞ –≤–∏–¥–µ–æ {y_id} –Ω–∞–π–¥–µ–Ω–∞ –≤ –∫—ç—à–µ")
        return metadata_cache[y_id]
    
    for attempt in range(3):
        try:
            cmd = [YT_DLP_PATH, "--dump-json"]
            
            # Critical: pass cookies for YouTube authentication
            if os.path.exists("youtube_cookies.txt"):
                cmd.extend(["--cookies", "youtube_cookies.txt"])
                log(f"üçÆ Using YouTube cookies for attempt {attempt + 1}...")
            else:
                log(f"‚ö†Ô∏è No YouTube cookies found! Attempt {attempt + 1} will likely fail.")
            
            cmd.append(f"https://youtube.com/watch?v={y_id}")
            
            res = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            if res.returncode == 0:
                data = json.loads(res.stdout)
                # Cache successful result
                if metadata_cache is not None:
                    metadata_cache[y_id] = data
                log(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–∞ –ø–æ–ª–Ω–∞—è –∏–Ω—Ñ–æ –¥–ª—è {y_id}")
                return data
            else:
                if "Sign in to confirm" in res.stderr or "bot" in res.stderr.lower():
                    log(f"‚ùå YouTube —Ç—Ä–µ–±—É–µ—Ç –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é! Cookies –∏—Å—Ç–µ–∫–ª–∏ –∏–ª–∏ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã.")
                    log(f"üìÑ –û–±–Ω–æ–≤–∏ YOUTUBE_COOKIES_TXT secret –≤ GitHub!")
                else:
                    log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ (attempt {attempt + 1}/3): {res.stderr[:200]}")
                
                if attempt < 2:
                    wait_time = (2 ** attempt) * 5  # Exponential backoff: 5s, 10s, 20s
                    log(f"‚è≥ –û–∂–∏–¥–∞—é {wait_time}s –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω—ã–º –ø–æ–ø—ã—Ç–æ–º...")
                    time.sleep(wait_time)
        
        except subprocess.TimeoutExpired:
            log(f"‚ö†Ô∏è Timeout –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ (attempt {attempt + 1}/3)")
        except Exception as e:
            log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {e} (attempt {attempt + 1}/3)")
    
    log(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ –¥–ª—è {y_id} –ø–æ—Å–ª–µ 3 –ø–æ–ø—ã—Ç–æ–∫")
    return None

def process_video(y_id, title, description, token):
    log(f"üöÄ –û–±—Ä–∞–±–æ—Ç–∫–∞: {title}")
    local_file_base = os.path.join(UPLOADS_DIR, y_id)
    local_video_path = f"{local_file_base}.mp4"
    local_thumb_path = f"{local_file_base}.jpg"
    
    # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ (—Ç–æ–ª—å–∫–æ –≤–∏–¥–µ–æ)
    if not os.path.exists(local_video_path):
        yt_cmd = [YT_DLP_PATH, "-f", "best[ext=mp4]", "-o", f"{local_file_base}.%(ext)s"]
        
        # CRITICAL: Use cookies for authentication
        if os.path.exists("youtube_cookies.txt"):
            yt_cmd.extend(["--cookies", "youtube_cookies.txt"])
            log(f"üçÆ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å cookies...")
        else:
            log(f"‚ö†Ô∏è –ù–µ—Ç cookies! –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –±–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ (–º–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å)...")
        
        yt_cmd.extend(["--retries", "5", "--fragment-retries", "5"])
        yt_cmd.append(f"https://youtube.com/watch?v={y_id}")
        
        log(f"üòÅ –ù–∞—á–∏–Ω–∞—é —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ...")
        result = subprocess.run(yt_cmd)

    if not os.path.exists(local_video_path):
        log(f"‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª –Ω–µ —Å–∫–∞—á–∞–ª—Å—è! –ü—Ä–æ–±–ª–µ–º—ã:")
        log(f"   ‚Ä¢ YouTube —Ç—Ä–µ–±—É–µ—Ç –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é (–æ–±–Ω–æ–≤–∏—Ç—å cookies)")
        log(f"   ‚Ä¢ GitHub Actions IP –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω YouTube")
        log(f"   ‚Ä¢ –í–∏–¥–µ–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ –≤ –≤–∞—à–µ–º —Ä–µ–≥–∏–æ–Ω–µ")
        return False

    # --- EXTERNAL UPLOAD (Catbox) ---
    def upload_to_catbox(path):
        log(f"üì¶ Uploading to Catbox (External Host)...")
        try:
            files = {'reqtype': (None, 'fileupload'), 'fileToUpload': open(path, 'rb')}
            resp = requests.post("https://catbox.moe/user/api.php", files=files, timeout=300)
            if resp.status_code == 200:
                return resp.text.strip()
            log(f"‚ùå Catbox Error: {resp.text}")
        except Exception as e:
            log(f"‚ùå Catbox Exception: {e}")
        return None

    # Try external upload first
    video_url = upload_to_catbox(local_video_path)
    
    # Fallback to local server if external fails
    if not video_url:
        log("‚ö†Ô∏è External upload failed. Falling back to Local Server URL.")
        video_url = f"https://{PUBLIC_DOMAIN}/rutube-webhook/static/{y_id}.mp4"
    else:
        log(f"‚úÖ External URL: {video_url}")
    # --------------------------------

    headers = {"Authorization": f"Token {token}"}
    payload = {
        "url": video_url,
        "title": title,
        "is_hidden": False,
        "category_id": 13,
        "description": description
    }

    r = requests.post("https://rutube.ru/api/video/", json=payload, headers=headers)
    if r.status_code in [200, 201]:
        data = r.json()
        rutube_video_id = data.get('id') or data.get('video_id')
        
        if not rutube_video_id:
            log(f"‚ùå ID –≤–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ! –°—Ç–∞—Ç—É—Å: {r.status_code}")
            log(f"üìÑ –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç API: {r.text}")
            return False
            
        log(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –Ω–∞ Rutube! ID: {rutube_video_id}")
        
        # –ñ–¥–µ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if wait_for_processing(rutube_video_id, token):
            log("‚úÖ Rutube: –í–∏–¥–µ–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ.")
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–∞–¥—Ä –æ–±–ª–æ–∂–∫–∏ (SAFE MODE)
            if set_cover_frame:
                try:
                    log(f"üñºÔ∏è –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–∞–¥—Ä–∞ 00:01 –¥–ª—è –≤–∏–¥–µ–æ {rutube_video_id}...")
                    set_cover_frame(rutube_video_id, title)
                except Exception as e:
                    log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∫–∞–¥—Ä–∞ (Playwright): {e}")
            else:
                log("‚ÑπÔ∏è –ü—Ä–æ–ø—É—Å–∫ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∫–∞–¥—Ä–∞ (Playwright –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω).")
        else:
            log("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ")

        # --- SOCIAL MEDIA UPLOAD ---
        if process_social_uploads:
            try:
                log("üì± –ù–∞—á–∏–Ω–∞—é –∑–∞–≥—Ä—É–∑–∫—É –≤ —Å–æ—Ü—Å–µ—Ç–∏ (TikTok/Instagram)...")
                success = process_social_uploads(local_video_path, title, description)
                if success:
                    log("‚úÖ –°–æ—Ü—Å–µ—Ç–∏: –£—Å–ø–µ—à–Ω–æ!")
                else:
                    log("‚ö†Ô∏è –°–æ—Ü—Å–µ—Ç–∏: –û—à–∏–±–∫–∞ –Ω–µ –Ω–∞—à–∞, –Ω–æ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–≥–ª–∞ –±—ã—Ç—å –ø—Ä–æ–≤–∞–ª–µ–Ω–∞")
            except Exception as e:
                log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ —Å–æ—Ü—Å–µ—Ç–∏: {e}")
        # ---------------------------

        # Cleanup local file to save space
        if os.path.exists(local_video_path):
            try:
                os.remove(local_video_path)
                log(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª: {local_video_path}")
            except Exception as e:
                log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")

        mark_video_synced(y_id, title)
        return True
    log(f"‚ùå Rutube API –æ—à–∏–±–∫–∞: {r.text}")
    return False

def sync():
    init_db()
    
    # Load metadata cache at start
    metadata_cache = load_metadata_cache()
    log(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω –∫—ç—à —Å {len(metadata_cache)} –≤–∏–¥–µ–æ")
    
    token = get_auth_token()
    if not token: 
        log("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω API")
        return False

    # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –≤–∏–¥–µ–æ
    cmd = [YT_DLP_PATH, "--dump-json", "--flat-playlist", "--playlist-end", "5"]
    if os.path.exists("youtube_cookies.txt"):
         cmd.extend(["--cookies", "youtube_cookies.txt"])
    cmd.append(YOUTUBE_CHANNEL_URL)
    
    res = subprocess.run(cmd, capture_output=True, text=True)

    if res.returncode != 0:
        log(f"‚ùå –û—à–∏–±–∫–∞ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è YT-DLP (Exit Code: {res.returncode})")
        log(f"üìù Stderr: {res.stderr[:300]}")
        return False
    
    videos = []
    try:
        for line in res.stdout.strip().split("\n"):
            if line: videos.append(json.loads(line))
    except json.JSONDecodeError as e:
        log(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
        return False
    
    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º top-5
    for vid in videos:
        y_id = vid.get('id')
        if not is_video_synced(y_id):
            # Fetch full details with caching
            full_info = get_full_video_info(y_id, metadata_cache)
            if full_info:
                title = full_info.get('title', vid.get('title'))
                description = full_info.get('description', vid.get('description', ''))
            else:
                title = vid.get('title')
                description = vid.get('description', '')
                log(f"‚ö†Ô∏è Using fallback metadata for {y_id}")
            
            result = process_video(y_id, title, description, token)
            # Save cache after processing
            save_metadata_cache(metadata_cache)
            return result

    # –ï—Å–ª–∏ –º—ã –∑–¥–µ—Å—å, –∑–Ω–∞—á–∏—Ç –≤—Å–µ top-5 —É–∂–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω—ã.
    if not videos:
        log("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ –Ω–∞ –∫–∞–Ω–∞–ª–µ (—Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç).")
        return True

    # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞—Ç—É —Å–∞–º–æ–≥–æ —Å–≤–µ–∂–µ–≥–æ –≤–∏–¥–µ–æ
    most_recent_date = None
    for vid in videos:
        d_str = vid.get('upload_date')
        if d_str:
            try:
                d = datetime.datetime.strptime(d_str, "%Y%m%d")
                if most_recent_date is None or d > most_recent_date:
                    most_recent_date = d
            except ValueError:
                pass
    
    should_expand = False
    if most_recent_date:
        days_diff = (datetime.datetime.now() - most_recent_date).days
        if days_diff > 7:
            should_expand = True
            log(f"üïµÔ∏è –ü–æ—Å–ª–µ–¥–Ω–µ–µ –≤–∏–¥–µ–æ –±—ã–ª–æ {days_diff} –¥–Ω. –Ω–∞–∑–∞–¥. –†–∞—Å—à–∏—Ä—è–µ–º –ø–æ–∏—Å–∫...")
    else:
        should_expand = True
    
    if should_expand:
        # 3. –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ (50 –≤–∏–¥–µ–æ)
        cmd_expanded = [YT_DLP_PATH, "--dump-json", "--flat-playlist", "--playlist-end", "50"]
        if os.path.exists("youtube_cookies.txt"):
            cmd_expanded.extend(["--cookies", "youtube_cookies.txt"])
        cmd_expanded.append(YOUTUBE_CHANNEL_URL)
        
        res_expanded = subprocess.run(cmd_expanded, capture_output=True, text=True)
        
        expanded_videos = []
        for line in res_expanded.stdout.strip().split("\n"):
            if line: expanded_videos.append(json.loads(line))
        
        for vid in expanded_videos:
            y_id = vid.get('id')
            if not is_video_synced(y_id):
                log(f"üï∞Ô∏è –ù–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ä–æ–µ –Ω–µ—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ: {vid.get('title')}")
                
                full_info = get_full_video_info(y_id, metadata_cache)
                if full_info:
                    title = full_info.get('title', vid.get('title'))
                    description = full_info.get('description', vid.get('description', ''))
                else:
                    title = vid.get('title')
                    description = vid.get('description', '')
                
                result = process_video(y_id, title, description, token)
                save_metadata_cache(metadata_cache)
                return result
        
        log("‚úÖ –í—Å–µ –≤–∏–¥–µ–æ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 50 —É–∂–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω—ã.")
    else:
        log("‚úÖ –í—Å–µ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –≤–∏–¥–µ–æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω—ã.")
    
    # Save cache before exit
    save_metadata_cache(metadata_cache)
    return True

if __name__ == "__main__":
    success = sync()
    if success is False:
        log("‚ùå Sync finished with errors.")
        sys.exit(1)
    log("‚úÖ Sync finished successfully.")
    sys.exit(0)
